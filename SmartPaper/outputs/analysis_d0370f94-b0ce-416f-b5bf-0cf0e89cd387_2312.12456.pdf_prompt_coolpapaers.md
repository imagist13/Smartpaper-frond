✨ 元数据信息 ✨

📄 处理URL: https://arxiv.org/pdf/2312.12456.pdf

💡 提示词模板: coolpapaers

📝 描述信息: 无

🚀 正在下载并转换PDF...

✅ PDF转换完成，开始分析...

使用提示词模式进行分析...
### **论文分析总结**

#### **1. 这篇论文是什么？**  
**概括：**  
论文《PowerInfer: Fast Large Language Model Serving with a Consumer-grade GPU》提出了一种高效的**大语言模型（LLM）推理引擎**，专为**消费级GPU（如NVIDIA RTX 4090）**设计。其核心思想是通过利用LLM推理中神经元激活的**局部性（power-law分布）**，将高频激活的“热神经元”预加载到GPU，低频激活的“冷神经元”卸载到CPU计算，从而减少GPU内存需求和CPU-GPU数据传输，显著提升推理速度。

---

#### **2. 这篇论文试图解决什么问题